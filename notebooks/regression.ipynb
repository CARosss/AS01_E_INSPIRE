{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-28T17:52:38.830416Z",
     "start_time": "2025-01-28T17:52:38.638052Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "from my_settings import log_transform_config, plotting, use_best_params\n",
    "from my_settings import one_hot as one_hot_encode\n",
    "\n",
    "print(log_transform_config)\n",
    "print(plotting, one_hot_encode, use_best_params)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age_mean_mass': False, 'velDisp_ppxf_res': True, 'MgFe': False, '[M/H]_mean_mass': False}\n",
      "False False True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:52:38.906723Z",
     "start_time": "2025-01-28T17:52:38.902390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_data(df, selected_features, log_transform_features=None, one_hot_encode=False):\n",
    "    X = df[selected_features].copy()\n",
    "    \n",
    "    # Store original MgFe for potential restoration\n",
    "    original_mgfe = X['MgFe'].copy() if 'MgFe' in X.columns else None\n",
    "    \n",
    "    if one_hot_encode and 'MgFe' in X.columns:\n",
    "        # Define bins and labels\n",
    "        bins = [0.0, 0.1, 0.2, 0.3, 0.4, np.inf]\n",
    "        mgfe_labels = ['MgFe_0.0', 'MgFe_0.1', 'MgFe_0.2', 'MgFe_0.3', 'MgFe_0.4']\n",
    "        \n",
    "        # Create binned version\n",
    "        X['MgFe_binned'] = pd.cut(X['MgFe'], \n",
    "                                 bins=bins, \n",
    "                                 labels=mgfe_labels, \n",
    "                                 include_lowest=True, \n",
    "                                 right=False)\n",
    "        \n",
    "        # One-hot encode the binned column\n",
    "        mgfe_encoded = pd.get_dummies(X['MgFe_binned'], prefix='', prefix_sep='')\n",
    "        \n",
    "        # Drop original and binned MgFe columns\n",
    "        X = X.drop(['MgFe', 'MgFe_binned'], axis=1)\n",
    "        \n",
    "        # Add encoded columns\n",
    "        X = pd.concat([X, mgfe_encoded], axis=1)\n",
    "    \n",
    "    if log_transform_features is None:\n",
    "        log_transform_features = {\n",
    "            'age_mean_mass': False,\n",
    "            'velDisp_ppxf_res': False,\n",
    "            '[M/H]_mean_mass': False\n",
    "        }\n",
    "\n",
    "    for feature, do_log in log_transform_features.items():\n",
    "        if do_log and feature in X.columns:\n",
    "            X[feature] = np.log10(X[feature] + 1e-10)\n",
    "    \n",
    "    return X, X.columns.tolist(), original_mgfe\n",
    "\n",
    "def restore_original_mgfe(df, original_mgfe, mgfe_labels=None):\n",
    "    if mgfe_labels is None:\n",
    "        mgfe_labels = ['MgFe_0.0', 'MgFe_0.1', 'MgFe_0.2', 'MgFe_0.3', 'MgFe_0.4']\n",
    "    \n",
    "    # Remove one-hot columns\n",
    "    df = df.drop(columns=[col for col in df.columns if col in mgfe_labels])\n",
    "    \n",
    "    # Restore original MgFe\n",
    "    if original_mgfe is not None:\n",
    "        df['MgFe'] = original_mgfe\n",
    "    \n",
    "    return df"
   ],
   "id": "bf20fd7fe47a0a3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:52:38.942203Z",
     "start_time": "2025-01-28T17:52:38.937228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_feature_importance(model, feature_names):\n",
    "    \"\"\"Plot feature importances for models that support them.\"\"\"\n",
    "    if hasattr(model.named_steps['regressor'], 'feature_importances_'):\n",
    "        importance = model.named_steps['regressor'].feature_importances_\n",
    "        indices = np.argsort(importance)[::-1]\n",
    "        \n",
    "        if plotting:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.title(\"Feature Importances\")\n",
    "            plt.bar(range(len(importance)), importance[indices])\n",
    "            plt.xticks(range(len(importance)), [feature_names[i] for i in indices], rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # Print numerical values\n",
    "        for i in indices:\n",
    "            print(f\"{feature_names[i]}: {importance[i]:.4f}\")\n",
    "    else:\n",
    "        print(\"This model doesn't support feature importances\")\n",
    "\n",
    "def plot_regression_results(y_true, y_pred, model_name):\n",
    "    \"\"\"Plot regression results with metrics.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(y_true, y_pred, alpha=0.5)\n",
    "\n",
    "    # Diagonal line for perfect predictions\n",
    "    min_val, max_val = 0, 1\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
    "\n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    ax.set_title(f'{model_name} Regression Results')\n",
    "    ax.set_xlabel('True Values')\n",
    "    ax.set_ylabel('Predicted Values')\n",
    "\n",
    "    text = (f'R² = {r2:.3f}\\n'\n",
    "            f'RMSE = {rmse:.3f}\\n'\n",
    "            f'MAE = {mae:.3f}')\n",
    "    ax.text(0.05, 0.95, text, transform=ax.transAxes,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "\n",
    "    return fig"
   ],
   "id": "2dd3bb4951ab816f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:52:38.968738Z",
     "start_time": "2025-01-28T17:52:38.959769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fit_and_evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    \"\"\"Train a model and evaluate its performance.\"\"\"\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    return {\n",
    "        'r2_score': r2_score(y_test, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        'mae': mean_absolute_error(y_test, y_pred),\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "\n",
    "def get_feature_importances(model, X, random_state, plotting=False):\n",
    "    \"\"\"Extract and optionally plot feature importances from a model.\"\"\"\n",
    "    if not hasattr(model, 'feature_importances_') and not hasattr(model, 'coef_'):\n",
    "        return None\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance = model.feature_importances_\n",
    "    else:  # For Lasso and Ridge\n",
    "        coef = np.abs(model.coef_)\n",
    "        importance = coef / np.sum(coef)\n",
    "    \n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    \n",
    "    if plotting:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(f\"Feature Importances (Seed {random_state})\")\n",
    "        plt.bar(range(len(importance)), importance[indices])\n",
    "        plt.xticks(range(len(importance)), [X.columns[i] for i in indices], rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    return importance\n",
    "\n",
    "def setup_random_search(model_name, model_info, random_state, n_iter = 100):\n",
    "    base_params = {\n",
    "        'n_iter': n_iter,\n",
    "        'cv': 5,\n",
    "        'scoring': 'neg_mean_squared_error',\n",
    "        'random_state': random_state,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': 1\n",
    "    }\n",
    "    \n",
    "    estimator_map = {\n",
    "        'XGBoost': XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            enable_categorical=False,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        'RandomForest': RandomForestRegressor(random_state=random_state),\n",
    "        'Lasso': Lasso(random_state=random_state),\n",
    "        'Ridge': Ridge(random_state=random_state)\n",
    "    }\n",
    "    \n",
    "    return RandomizedSearchCV(\n",
    "        estimator=estimator_map[model_name],\n",
    "        param_distributions=model_info['params'],\n",
    "        **base_params\n",
    "    )\n",
    "\n",
    "def print_results_summary(results, X, feature_names):\n",
    "    \"\"\"Print average results and save feature importances and best parameters across seeds.\"\"\"\n",
    "    print(\"\\n=== Average Results Across Seeds ===\")\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"R² Score: {np.mean(metrics['r2_scores']):.4f} ± {np.std(metrics['r2_scores']):.4f}\")\n",
    "        print(f\"RMSE: {np.mean(metrics['rmse_scores']):.4f} ± {np.std(metrics['rmse_scores']):.4f}\")\n",
    "        print(f\"MAE: {np.mean(metrics['mae_scores']):.4f} ± {np.std(metrics['mae_scores']):.4f}\")\n",
    "        \n",
    "        # Save best parameters if available\n",
    "        if 'best_params' in metrics and metrics['best_params']:\n",
    "            print(\"\\nBest Parameters Across Seeds:\")\n",
    "            params_df = pd.DataFrame([p['params'] for p in metrics['best_params']])\n",
    "            \n",
    "            print(\"\\nParameter Statistics:\")\n",
    "            print(params_df.describe())\n",
    "            \n",
    "            print(\"\\nCV Scores for Best Parameters:\")\n",
    "            for param_info in metrics['best_params']:\n",
    "                print(f\"Seed {param_info['seed']}: {param_info['cv_score']:.4f}\")\n",
    "            \n",
    "            # Save parameters\n",
    "            os.makedirs('../data/regression_results', exist_ok=True)\n",
    "            params_df.to_csv(f'../data/regression_results/{name}_best_params.csv', index=False)\n",
    "        \n",
    "        # Calculate and save feature importances\n",
    "        if metrics['importances']:\n",
    "            mean_importance = np.mean(metrics['importances'], axis=0)\n",
    "            std_importance = np.std(metrics['importances'], axis=0)\n",
    "            \n",
    "            print(\"\\nAverage Feature Importances:\")\n",
    "            for i, (mean, std) in enumerate(zip(mean_importance, std_importance)):\n",
    "                print(f\"{X.columns[i]}: {mean:.4f} ± {std:.4f}\")\n",
    "            \n",
    "            # Create DataFrame with feature importances and save\n",
    "            importance_df = pd.DataFrame({\n",
    "                'Feature': feature_names,\n",
    "                'Mean_Importance': mean_importance,\n",
    "                'Std_Importance': std_importance\n",
    "            })\n",
    "            \n",
    "            # Sort by mean importance before saving\n",
    "            importance_df = importance_df.sort_values('Mean_Importance', ascending=False)\n",
    "            \n",
    "            # Save importances\n",
    "            os.makedirs('../data/regression_results', exist_ok=True)\n",
    "            importance_df.to_csv(f'../data/regression_results/{name}_avg.csv', index=False)\n",
    "\n",
    "def comprehensive_regression_analysis(X, y, test_size=0.2, seeds=[42], n_iter=100):\n",
    "    \"\"\"Main function to perform comprehensive regression analysis.\"\"\"\n",
    "    all_results = {name: {'r2_scores': [], 'rmse_scores': [], 'mae_scores': [], 'importances': [],             'best_params': []} \n",
    "                  for name in models.keys()}\n",
    "    \n",
    "    for random_state in seeds:\n",
    "        print(f\"\\nRunning with random seed {random_state}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        for name, model_info in models.items():\n",
    "            print(f\"\\nEvaluating {name}...\")\n",
    "            \n",
    "            if model_info['params']:\n",
    "                random_search = setup_random_search(name, model_info, random_state, n_iter)\n",
    "                random_search.fit(X_train_scaled, y_train)\n",
    "                best_model = random_search.best_estimator_\n",
    "                print(\"Best Parameters:\", random_search.best_params_)\n",
    "                \n",
    "                all_results[name]['best_params'].append({\n",
    "                    'seed': random_state,\n",
    "                    'params': random_search.best_params_,\n",
    "                    'cv_score': random_search.best_score_\n",
    "                })\n",
    "                evaluation = fit_and_evaluate_model(best_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "            else:\n",
    "                model = clone(model_info['model'])\n",
    "                evaluation = fit_and_evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "            \n",
    "            # Store results\n",
    "            all_results[name]['r2_scores'].append(evaluation['r2_score'])\n",
    "            all_results[name]['rmse_scores'].append(evaluation['rmse'])\n",
    "            all_results[name]['mae_scores'].append(evaluation['mae'])\n",
    "            \n",
    "            importance = get_feature_importances(best_model if model_info['params'] else model, X, random_state, plotting)\n",
    "            if importance is not None:\n",
    "                all_results[name]['importances'].append(importance)\n",
    "            \n",
    "            if plotting:\n",
    "                plot_regression_results(y_test, evaluation['y_pred'], f\"{name} (Seed {random_state})\")\n",
    "                plt.show()\n",
    "\n",
    "    print_results_summary(all_results, X, feature_names)\n",
    "    return all_results\n"
   ],
   "id": "db34012cb8e0b7ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:52:38.978962Z",
     "start_time": "2025-01-28T17:52:38.973358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/E-INSPIRE_I_master_catalogue.csv')\n",
    "np.random.seed(42)"
   ],
   "id": "b880ee1f59c05ce4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:52:39.002214Z",
     "start_time": "2025-01-28T17:52:38.994193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    'RandomForest': {\n",
    "        'model': None,\n",
    "        'params': {\n",
    "            'n_estimators': randint(400, 600),      # Wider range to ensure we're not missing better values\n",
    "            'max_depth': randint(10, 30),             # Include shallower and deeper trees\n",
    "            'min_samples_split': randint(2, 20),     # Include more conservative splits\n",
    "            'max_features': uniform(0.2, 0.8),       # Wider feature consideration range\n",
    "            'max_samples': uniform(0.3, 0.7),        # This range is good as is\n",
    "            'min_samples_leaf': randint(1, 6)        # Allow for more conservative leaf sizes\n",
    "        }\n",
    "    },\n",
    "}\n",
    "all = { \n",
    "    'XGBoost': {\n",
    "        'model': None,\n",
    "        'params': {\n",
    "            # Current parameters\n",
    "            'n_estimators': randint(200, 500),    \n",
    "            'max_depth': randint(3, 15),           \n",
    "            'learning_rate': loguniform(0.01, 0.3),  \n",
    "            'subsample': uniform(0.3, 0.7),        \n",
    "            'min_child_weight': randint(3, 7),\n",
    "            'colsample_bytree': uniform(0.3, 0.7),  # Fraction of features to use per tree\n",
    "            'gamma': loguniform(0.005, 0.1),         # Minimum loss reduction for split\n",
    "            'reg_alpha': loguniform(0.001, 0.01),      # L1 regularization\n",
    "            'reg_lambda': loguniform(0.1, 1),     # L2 regularization\n",
    "            }\n",
    "    },\n",
    "    'Linear Regression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}\n",
    "    },\n",
    "        'Lasso': {\n",
    "        'model': None,\n",
    "        'params': {\n",
    "            'alpha': loguniform(1e-4, 1),\n",
    "            'max_iter': [2000],  # Increased max iterations to ensure convergence\n",
    "            'tol': loguniform(1e-6, 1e-4)\n",
    "        }\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'model': None,\n",
    "        'params': {\n",
    "            'alpha': loguniform(1e-4, 1),\n",
    "            'max_iter': [2000],\n",
    "            'tol': loguniform(1e-6, 1e-4)\n",
    "        }\n",
    "    },\n",
    "}\n"
   ],
   "id": "37e6be9371f37c1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:52:39.261425Z",
     "start_time": "2025-01-28T17:52:39.006317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select features for the analysis\n",
    "selected_features = ['MgFe', '[M/H]_mean_mass', 'velDisp_ppxf_res', 'age_mean_mass']\n",
    "\n",
    "# Preprocess data\n",
    "X, feature_names, original_mgfe = preprocess_data(\n",
    "    df, \n",
    "    selected_features, \n",
    "    log_transform_features=log_transform_config,\n",
    "    one_hot_encode=one_hot_encode\n",
    ")\n",
    "y = df['DoR'].values\n",
    "seeds = [42,43,45]\n",
    "if not use_best_params:\n",
    "    results = comprehensive_regression_analysis(X, y, test_size=0.2, seeds=seeds, n_iter=500)\n",
    "else:\n",
    "    best_params = pd.read_csv('../data/regression_results/RandomForest_best_params.csv').mean()\n",
    "    \n",
    "    best_params = {\n",
    "       'max_depth': int(round(best_params['max_depth'])),  # Round to nearest integer\n",
    "       'max_features': round(best_params['max_features'], 3),\n",
    "       'max_samples': round(best_params['max_samples'], 3),\n",
    "       'min_samples_leaf': int(best_params['min_samples_leaf']),\n",
    "       'min_samples_split': int(round(best_params['min_samples_split'])),\n",
    "       'n_estimators': int(round(best_params['n_estimators']))\n",
    "    }\n",
    "    \n",
    "    print(\"Using best parameters:\", best_params)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Create and train model with best params\n",
    "    rf = RandomForestRegressor(**best_params)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get predictions for test set\n",
    "    y_pred = rf.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate and print metrics for test set\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    # Print feature importances\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    for feature, importance in zip(feature_names, rf.feature_importances_):\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "    \n",
    "    # Plot test set results\n",
    "    if plotting:\n",
    "        fig = plot_regression_results(y_test, y_pred, \"Test Set Performance\")\n",
    "        plt.show()\n",
    "        \n",
    "    # Now for full dataset\n",
    "    print(\"\\nFull Dataset Performance:\")\n",
    "    X_full_scaled = scaler.fit_transform(X)  # Scale the full dataset\n",
    "    y_full_pred = rf.predict(X_full_scaled)\n",
    "    \n",
    "    print(f\"R² Score: {r2_score(y, y_full_pred):.4f}\")\n",
    "    print(f\"RMSE: {np.sqrt(mean_squared_error(y, y_full_pred)):.4f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y, y_full_pred):.4f}\")\n",
    "    \n",
    "    if plotting:\n",
    "        fig = plot_regression_results(y, y_full_pred, \"Full Dataset Performance\")\n",
    "        plt.show()\n",
    "\n",
    "if one_hot_encode:  \n",
    "    X = restore_original_mgfe(X, original_mgfe)"
   ],
   "id": "2b659986bda91d68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using best parameters: {'max_depth': 22, 'max_features': 0.793, 'max_samples': 0.5, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 460}\n",
      "\n",
      "Test Set Performance:\n",
      "R² Score: 0.8019\n",
      "RMSE: 0.0723\n",
      "MAE: 0.0541\n",
      "\n",
      "Feature Importances:\n",
      "MgFe: 0.0239\n",
      "[M/H]_mean_mass: 0.2761\n",
      "velDisp_ppxf_res: 0.0672\n",
      "age_mean_mass: 0.6328\n",
      "\n",
      "Full Dataset Performance:\n",
      "R² Score: 0.8288\n",
      "RMSE: 0.0618\n",
      "MAE: 0.0433\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T17:52:39.283601Z",
     "start_time": "2025-01-28T17:52:39.278106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def form_regression_clusters(df, value_1=0.3, value_2=0.6):\n",
    "    # Create SDSS identifiers\n",
    "    sdss_ids = [f\"spec-{int(plate):04d}-{int(mjd):05d}-{int(fiber):04d}.fits\" \n",
    "                for plate, mjd, fiber in zip(df['plate'], df['mjd'], df['fiberid'])]\n",
    "    \n",
    "    # Assign clusters based on DoR values\n",
    "    dor_labels = np.zeros(len(df), dtype=int)\n",
    "    dor_labels[(df['DoR'] >= value_1) & (df['DoR'] < value_2)] = 1\n",
    "    dor_labels[df['DoR'] < value_1] = 2\n",
    "    \n",
    "    # Create DataFrame with results\n",
    "    results_df = pd.DataFrame({\n",
    "        'SDSS_ID': sdss_ids,\n",
    "        'Cluster': dor_labels\n",
    "    })\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs('../data/cluster_results', exist_ok=True)\n",
    "    \n",
    "    # Save results\n",
    "    filename = '../data/cluster_results/regression_tails_clusters.csv'\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nCluster Summary:\")\n",
    "    for i, label in enumerate(['High DoR', 'Medium DoR', 'Low DoR']):\n",
    "        mask = dor_labels == i\n",
    "        print(f\"Cluster {i} ({label}): {mask.sum()} galaxies\")\n",
    "        print(f\"Mean DoR: {df.loc[mask, 'DoR'].mean():.3f}\")\n",
    "\n",
    "form_regression_clusters(df, value_1=0.2, value_2=0.65)"
   ],
   "id": "b70aadc3869a838d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Summary:\n",
      "Cluster 0 (High DoR): 54 galaxies\n",
      "Mean DoR: 0.738\n",
      "Cluster 1 (Medium DoR): 361 galaxies\n",
      "Mean DoR: 0.471\n",
      "Cluster 2 (Low DoR): 15 galaxies\n",
      "Mean DoR: 0.136\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
