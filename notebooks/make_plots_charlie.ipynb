{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plots for paper"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "from ppxf.ppxf import ppxf\n",
    "import ppxf.ppxf_util as util\n",
    "import ppxf.sps_util as lib\n",
    "from copy import copy\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "\n",
    "from scripts.ned_calculator import NedCalculator"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def read_fits_summary(fitsfile):\n",
    "    \n",
    "    hdu = fits.open(fitsfile)\n",
    "\n",
    "    age_grid = hdu['age_grid'].data\n",
    "    weights = hdu['pp_weights'].data.reshape(hdu['reg_dim'].data)\n",
    "\n",
    "    name = hdu[0].header['name']\n",
    "    z = hdu[0].header['z']\n",
    "    hdu.close()\n",
    "    del hdu\n",
    "\n",
    "    wei1 = weights.sum(axis=1)\n",
    "    wei1/=wei1.sum()\n",
    "\n",
    "    wei1_rev = copy(wei1[::-1])\n",
    "\n",
    "    ages = age_grid[:,0]\n",
    "\n",
    "    weiplot = np.cumsum(wei1_rev)\n",
    "\n",
    "    nedcalc = NedCalculator(z)\n",
    "    univ_age = nedcalc.zage_Gyr\n",
    "\n",
    "    ages1 = univ_age - ages\n",
    "\n",
    "    agesplot = np.concatenate([np.array([univ_age]), ages1, np.array([0.])])\n",
    "    weiplot = np.concatenate([np.array([0.]), weiplot, np.array([weiplot[-1]])])\n",
    "\n",
    "    agesplot = copy(agesplot[::-1])\n",
    "    \n",
    "    return name,z,agesplot,weiplot,univ_age"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_csv('../outputs/stacked_catalogues/CATALOGUE_REGRESSION.csv')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Computer Modern\",\n",
    "    \"figure.dpi\": 300,\n",
    "    \"font.size\": 15,\n",
    "})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"import numpy as np\n",
    "import os\n",
    "\n",
    "def make_safe_npz(original_file, safe_file):\n",
    "    # Load the original data\n",
    "    data = np.load(original_file, allow_pickle=True)\n",
    "    \n",
    "    # Extract all arrays\n",
    "    templates = data['templates']\n",
    "    masses = data['masses']\n",
    "    ages = data['ages']\n",
    "    metals = data['metals']\n",
    "    lam = data['lam']\n",
    "    fwhm = data['fwhm']\n",
    "    \n",
    "    # Print original metallicity values\n",
    "    print(\"Original metallicity values:\")\n",
    "    print(metals)\n",
    "    print(f\"Shape of original templates: {templates.shape}\")\n",
    "    \n",
    "    metals = np.array([-1.49, -1.26, -0.96, -0.66, -0.35, -0.25, 0.06, 0.15, 0.26])\n",
    "    \n",
    "    # Save the filtered data\n",
    "    np.savez(safe_file, \n",
    "             templates=templates,\n",
    "             masses=masses,\n",
    "             ages=ages,\n",
    "             metals=metals,\n",
    "             lam=lam,\n",
    "             fwhm=fwhm)\n",
    "    \n",
    "    print(f\"\\nCreated new file: {safe_file}\")\n",
    "\n",
    "loc1 = '../data/MILES_SSP/' \n",
    "loc2 = '../data/MILES_SSP_SAFE/' \n",
    "\n",
    "# Make sure the target directory exists\n",
    "os.makedirs(loc2, exist_ok=True)\n",
    "\n",
    "# Process files from alpha0.npz to alpha4.npz\n",
    "for i in range(5):  # 0 to 4 inclusive\n",
    "    original_file = f\"{loc1}alpha{i}.npz\"\n",
    "    safe_file = f\"{loc2}alpha{i}_safe.npz\"\n",
    "    \n",
    "    print(f\"\\nProcessing file: alpha{i}.npz\")\n",
    "    \n",
    "    # Check if original file exists\n",
    "    if os.path.exists(original_file):\n",
    "        try:\n",
    "            make_safe_npz(original_file, safe_file)\n",
    "            print(f\"Successfully processed alpha{i}.npz\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing alpha{i}.npz: {e}\")\n",
    "    else:\n",
    "        print(f\"Original file {original_file} not found. Skipping.\")\n",
    "\n",
    "print(\"\\nAll files processed.\")\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"from numpy import load\n",
    "\n",
    "file = '../data/MILES_SSP_SAFE/alpha2_safe.npz'\n",
    "data = np.load(file, allow_pickle=True)\n",
    "\n",
    "# Extract all arrays\n",
    "templates = data['templates']\n",
    "masses = data['masses']\n",
    "ages = data['ages']\n",
    "metals = data['metals']\n",
    "lam = data['lam']\n",
    "fwhm = data['fwhm']\n",
    "\n",
    "print(metals)\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Figure 7"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lam_range_temp = [1000, 1e4]\n",
    "vel = 0                 # Spectrum is de-redshifted --> starting guess is zero\n",
    "start = [vel, 200.]     # (km/s), starting guess for [V, sigma]\n",
    "tie_balmer = True\n",
    "limit_doublets = True\n",
    "c = 299792.458  # speed of light in km/s\n",
    "regul_err = 0.1 # Large regularization error\n",
    "vel = 0   # eq.(8) of Cappellari (2017)\n",
    "moments = [4, 2, 2]\n",
    "gas_reddening = 0 if tie_balmer else None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "row = df[df['filename']==\"data/stacked_fits/stacked_REGRESSION_0.fits\"].iloc[0]\n",
    "hdu = fits.open('../data/stacked_fits/stacked_REGRESSION_0.fits', ignore_missing_simple=True)\n",
    "\n",
    "t = hdu['COADD'].data\n",
    "\n",
    "galaxy1 = t['flux']/np.median(t['flux'])     # Normalize spectrum to avoid numerical issues\n",
    "ln_lam_gal = np.log(t['wave'])\n",
    "# ln_lam_gal = t['loglam']*np.log(10)         # Convert lg --> ln\n",
    "wave1 = np.exp(ln_lam_gal)\n",
    "\n",
    "redshift = 0\n",
    "sigma = row['vel_disp_avg']\n",
    "alpha = row['alpha']\n",
    "print(\"alpha\",alpha)\n",
    "# alpha = int(alpha)/10\n",
    "\n",
    "if alpha < 0:\n",
    "    alpha = '0'\n",
    "elif alpha > 0.4:\n",
    "    alpha = '4'\n",
    "else:\n",
    "    alpha = str(int(alpha*10))\n",
    "print(\"alpha\",alpha)\n",
    "\n",
    "wave1 = wave1/(1 + redshift)  # Compute wave in the galaxy rest frame\n",
    "galaxy1 = galaxy1[(wave1 > 3600) & (wave1 < 6500)]\n",
    "wave1 = wave1[(wave1 > 3600) & (wave1 < 6500)]\n",
    "\n",
    "wave1 *= np.median(util.vac_to_air(wave1)/wave1)\n",
    "\n",
    "noise = np.full_like(galaxy1, 0.0163)  # Assume constant noise per pixel here\n",
    "\n",
    "d_ln_lam = np.log(wave1[-1]/wave1[0])/(wave1.size - 1)  # Average ln_lam step\n",
    "velscale = c*d_ln_lam                   # eq. (8) of Cappellari (2017)\n",
    "FWHM_gal = 2.76/(1+redshift)  # SDSS has an approximate instrumental resolution FWHM of 2.76A.\n",
    "\n",
    "# filename = f'../data/MILES_SSP/alpha{alpha}.npz'\n",
    "filename = f'../data/MILES_SSP_SAFE/alpha{alpha}.npz'\n",
    "\n",
    "print(\"filename\",filename)\n",
    "\n",
    "sps1 = lib.sps_lib(filename, velscale, FWHM_gal, age_range=[0, NedCalculator(redshift).zage_Gyr], metal_range=[-2, 0.5])\n",
    "\n",
    "reg_dim = sps1.templates.shape[1:]\n",
    "stars_templates = sps1.templates.reshape(sps1.templates.shape[0], -1)\n",
    "\n",
    "lam_range_gal = np.array([np.min(wave1), np.max(wave1)])\n",
    "\n",
    "gas_templates, gas_names, line_wave = util.emission_lines(\n",
    "sps1.ln_lam_temp, lam_range_gal, FWHM_gal, tie_balmer=tie_balmer,\n",
    "limit_doublets=limit_doublets)\n",
    "\n",
    "templates = np.column_stack([stars_templates, gas_templates])\n",
    "\n",
    "start = [vel, sigma]     # (km/s), starting guess for [V, sigma]\n",
    "\n",
    "n_temps = stars_templates.shape[1]\n",
    "n_forbidden = np.sum([\"[\" in a for a in gas_names])  # forbidden lines contain \"[*]\"\n",
    "n_balmer = len(gas_names) - n_forbidden\n",
    "\n",
    "component = [0]*n_temps + [1]*n_balmer + [2]*n_forbidden\n",
    "gas_component = np.array(component) > 0  # gas_component=True for gas templates\n",
    "\n",
    "start = [start, start, start]\n",
    "\n",
    "pp = ppxf(templates, galaxy1, noise, velscale, start, moments=moments,\n",
    "        degree=-1, mdegree=8, lam=wave1, lam_temp=sps1.lam_temp,\n",
    "        regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "        gas_component=gas_component, gas_names=gas_names,\n",
    "        gas_reddening=gas_reddening, quiet=True)\n",
    "\n",
    "noise = noise*np.sqrt(pp.chi2)\n",
    "\n",
    "pp_high = ppxf(templates, galaxy1, noise, velscale, start, moments=moments,\n",
    "            degree=-1, mdegree=8, lam=wave1, lam_temp=sps1.lam_temp,\n",
    "            regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "            gas_component=gas_component, gas_names=gas_names,\n",
    "            gas_reddening=gas_reddening, clean=True, quiet=True)\n",
    "\n",
    "weights_high = pp_high.weights[~gas_component]                # Exclude weights of the gas templates\n",
    "weights_high = weights_high.reshape(reg_dim)/weights_high.sum() \n",
    "\n",
    "print(\"chi^2=\",pp_high.chi2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "row = df[df['filename']==\"data/stacked_fits/stacked_REGRESSION_2.fits\"].iloc[0]\n",
    "hdu = fits.open('../data/stacked_fits/stacked_REGRESSION_2.fits', ignore_missing_simple=True)\n",
    "\n",
    "t = hdu['COADD'].data\n",
    "\n",
    "galaxy = t['flux']/np.median(t['flux'])     # Normalize spectrum to avoid numerical issues\n",
    "ln_lam_gal = np.log(t['wave'])\n",
    "# ln_lam_gal = t['loglam']*np.log(10)         # Convert lg --> ln\n",
    "wave = np.exp(ln_lam_gal)\n",
    "\n",
    "redshift = 0\n",
    "sigma = row['vel_disp_avg']\n",
    "alpha = row['alpha']\n",
    "print(\"alphap1\",alpha)\n",
    "# alpha = int(alpha)/10\n",
    "\n",
    "if alpha < 0:\n",
    "    alpha = '0'\n",
    "elif alpha > 0.4:\n",
    "    alpha = '4'\n",
    "else:\n",
    "    alpha = str(int(alpha*10))\n",
    "\n",
    "print(\"alphap2\",alpha)\n",
    "\n",
    "wave = wave/(1 + redshift)  # Compute wave in the galaxy rest frame\n",
    "galaxy = galaxy[(wave > 3600) & (wave < 6500)]\n",
    "wave = wave[(wave > 3600) & (wave < 6500)]\n",
    "\n",
    "wave *= np.median(util.vac_to_air(wave)/wave)\n",
    "\n",
    "noise = np.full_like(galaxy, 0.0163)  # Assume constant noise per pixel here\n",
    "\n",
    "d_ln_lam = np.log(wave[-1]/wave[0])/(wave.size - 1)  # Average ln_lam step\n",
    "velscale = c*d_ln_lam                   # eq. (8) of Cappellari (2017)\n",
    "FWHM_gal = 2.76/(1+redshift)  # SDSS has an approximate instrumental resolution FWHM of 2.76A.\n",
    "\n",
    "# filename = f'../data/MILES_SSP/alpha{alpha}.npz'\n",
    "filename = f'../data/MILES_SSP_SAFE/alpha{alpha}.npz'\n",
    "print(\"filename\",filename)\n",
    "\n",
    "sps2 = lib.sps_lib(filename, velscale, FWHM_gal, age_range=[0, NedCalculator(redshift).zage_Gyr], metal_range=[-2, 0.35])\n",
    "\n",
    "reg_dim = sps2.templates.shape[1:]\n",
    "stars_templates = sps2.templates.reshape(sps2.templates.shape[0], -1)\n",
    "\n",
    "lam_range_gal = np.array([np.min(wave), np.max(wave)])\n",
    "\n",
    "gas_templates, gas_names, line_wave = util.emission_lines(\n",
    "sps2.ln_lam_temp, lam_range_gal, FWHM_gal, tie_balmer=tie_balmer,\n",
    "limit_doublets=limit_doublets)\n",
    "\n",
    "templates = np.column_stack([stars_templates, gas_templates])\n",
    "\n",
    "start = [vel, sigma]     # (km/s), starting guess for [V, sigma]\n",
    "\n",
    "n_temps = stars_templates.shape[1]\n",
    "n_forbidden = np.sum([\"[\" in a for a in gas_names])  # forbidden lines contain \"[*]\"\n",
    "n_balmer = len(gas_names) - n_forbidden\n",
    "\n",
    "component = [0]*n_temps + [1]*n_balmer + [2]*n_forbidden\n",
    "gas_component = np.array(component) > 0  # gas_component=True for gas templates\n",
    "\n",
    "start = [start, start, start]\n",
    "\n",
    "pp = ppxf(templates, galaxy, noise, velscale, start, moments=moments,\n",
    "        degree=-1, mdegree=8, lam=wave, lam_temp=sps2.lam_temp,\n",
    "        regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "        gas_component=gas_component, gas_names=gas_names,\n",
    "        gas_reddening=gas_reddening, quiet=True)\n",
    "\n",
    "noise = noise*np.sqrt(pp.chi2)\n",
    "\n",
    "pp_low = ppxf(templates, galaxy, noise, velscale, start, moments=moments,\n",
    "            degree=-1, mdegree=8, lam=wave, lam_temp=sps2.lam_temp,\n",
    "            regul=1/regul_err, reg_dim=reg_dim, component=component,\n",
    "            gas_component=gas_component, gas_names=gas_names,\n",
    "            gas_reddening=gas_reddening, clean=True, quiet=True)\n",
    "\n",
    "weights_low = pp_low.weights[~gas_component]                # Exclude weights of the gas templates\n",
    "weights_low = weights_low.reshape(reg_dim)/weights_low.sum()    # Normalized"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def make_ppxf_plot(pp_curr, sps_curr, weights_curr, textstr, path,type, colour='afmhot'):\n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize=(25, 10))\n",
    "    gs = gridspec.GridSpec(2, 2, width_ratios=[3, 1])\n",
    "    props = dict(boxstyle='square', facecolor='white', alpha=0.8, edgecolor='black')\n",
    "    hor_align = 0.92\n",
    "    ver_align = 0.21\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    pp_curr.plot()\n",
    "    ax1.set_xlim(0.36, 0.65)\n",
    "\n",
    "    ax1.set_xlabel(r'Wavelength (\\AA)', fontsize=16)\n",
    "    ax1.grid(False)  # Remove grid\n",
    "    ax1.text(hor_align, ver_align, textstr, transform=ax1.transAxes, fontsize=30,\n",
    "            verticalalignment='top', bbox=props, ha='center', linespacing=1.5)\n",
    "    \n",
    "    # Convert x-axis from microns to Angstroms if needed\n",
    "    # Check if current ticks are in microns by seeing if they're all < 10\n",
    "    current_ticks = ax1.get_xticks()\n",
    "    if all(tick < 10 for tick in current_ticks):\n",
    "        # Current ticks are in microns, convert to Angstroms\n",
    "        ax1.set_xticklabels([f\"{tick*10000:.0f}\" for tick in current_ticks])\n",
    "    # Second subplot - weights\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "\n",
    "    sps_curr.plot(weights_curr, cmap=colour)\n",
    "    if type!='low':\n",
    "        ax2.set_xlabel('')\n",
    "        ax1.set_xlabel('')\n",
    "        plt.setp(ax1.get_xticklabels(), visible=False)  # Hide x-tick labels for first plot\n",
    "        plt.setp(ax2.get_xticklabels(), visible=False)  # Hide x-tick labels for second plot\n",
    "    else:\n",
    "        plt.setp(ax1.get_xticklabels(), visible=True)\n",
    "        plt.setp(ax2.get_xticklabels(), visible=True)\n",
    "    \n",
    "    ax2.set_title('')\n",
    "    ax2.grid(False)  # Remove grid    \n",
    "    # Final adjustments\n",
    "    plt.tight_layout()\n",
    "    fig.align_ylabels([ax1])\n",
    "    # Save the figure\n",
    "    plt.savefig(path, bbox_inches='tight', dpi=300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pp_curr = pp_high\n",
    "sps_curr = sps1\n",
    "weights_curr = weights_high\n",
    "textstr = 'High DoR'\n",
    "path = '../outputs/make_plots_output/stellar_pop_fit_high.png'\n",
    "type = 'high'\n",
    "make_ppxf_plot(pp_curr, sps_curr, weights_curr, textstr, path,type, colour='gist_heat_r')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pp_curr = pp_low\n",
    "sps_curr = sps2\n",
    "weights_curr = weights_low\n",
    "textstr = 'Low DoR'\n",
    "path = '../outputs/make_plots_output/stellar_pop_fit_low.png'\n",
    "type = 'low'\n",
    "make_ppxf_plot(pp_curr, sps_curr, weights_curr, textstr, path,type, colour = 'gist_heat_r')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Figure 7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def make_ppxf_plots_overlaid(pp_high, pp_low, high_text=\"High DoR\", low_text=\"Low DoR\", \n",
    "                            y_offset=0.0, path=\"overlaid_spectra_plot.png\", \n",
    "                            normalize_at_wavelength=4000.0):\n",
    "    \n",
    "    fig = plt.figure(figsize=(25, 10))\n",
    "    \n",
    "    # First, let the high DoR ppxf object plot itself (creates its own axes)\n",
    "    pp_high.plot()\n",
    "    \n",
    "    # Get the current axes that ppxf.plot() created\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Get the data from both ppxf objects\n",
    "    wave_high = pp_high.lam\n",
    "    galaxy_high = pp_high.galaxy\n",
    "    bestfit_high = pp_high.bestfit\n",
    "    \n",
    "    wave_low = pp_low.lam\n",
    "    galaxy_low = pp_low.galaxy\n",
    "    bestfit_low = pp_low.bestfit\n",
    "    \n",
    "    # Normalize at the specified wavelength\n",
    "    if normalize_at_wavelength is not None:\n",
    "        # Find the closest index to the normalization wavelength for both spectra\n",
    "        idx_high = np.argmin(np.abs(wave_high - normalize_at_wavelength))\n",
    "        idx_low = np.argmin(np.abs(wave_low - normalize_at_wavelength))\n",
    "        \n",
    "        # Get flux values at those wavelengths\n",
    "        flux_high_at_norm = galaxy_high[idx_high]\n",
    "        flux_low_at_norm = galaxy_low[idx_low]\n",
    "        \n",
    "        # Calculate normalization factors\n",
    "        norm_factor_high = 1.0  # Keep high DoR spectrum as reference\n",
    "        norm_factor_low = flux_high_at_norm / flux_low_at_norm\n",
    "        \n",
    "        # Apply normalization\n",
    "        galaxy_high_norm = galaxy_high * norm_factor_high\n",
    "        bestfit_high_norm = bestfit_high * norm_factor_high\n",
    "        galaxy_low_norm = galaxy_low * norm_factor_low\n",
    "        bestfit_low_norm = bestfit_low * norm_factor_low\n",
    "        \n",
    "        print(f\"Normalizing spectra at wavelength {wave_high[idx_high]:.2f}Å\")\n",
    "        print(f\"High DoR flux at normalization: {flux_high_at_norm:.4f}\")\n",
    "        print(f\"Low DoR flux at normalization: {flux_low_at_norm:.4f}\")\n",
    "        print(f\"Normalization factor for Low DoR: {norm_factor_low:.4f}\")\n",
    "    else:\n",
    "        # If no normalization is requested, use original values\n",
    "        galaxy_high_norm = galaxy_high\n",
    "        bestfit_high_norm = bestfit_high\n",
    "        galaxy_low_norm = galaxy_low\n",
    "        bestfit_low_norm = bestfit_low\n",
    "    \n",
    "    # Clear the existing plot but keep the axes\n",
    "    ax.clear()\n",
    "    \n",
    "    # Create a custom color scheme\n",
    "    high_color = 'green'\n",
    "    high_bestfit_color = 'red'\n",
    "    \n",
    "    low_color = 'blue'\n",
    "    low_bestfit_color = 'green'\n",
    "    \n",
    "    # Plot high DoR data and best fit\n",
    "    ax.plot(wave_high, galaxy_high_norm, color=high_color, lw=1, label=f'{high_text} Data')\n",
    "    # ax.plot(wave_high, bestfit_high_norm, color=high_bestfit_color, lw=2, label=f'{high_text} Best Fit')\n",
    "    \n",
    "    # Plot low DoR data and best fit with the specified y-offset\n",
    "    ax.plot(wave_low, galaxy_low_norm + y_offset, color=low_color, lw=1, label=f'{low_text} Data')\n",
    "    # ax.plot(wave_low, bestfit_low_norm + y_offset, color=low_bestfit_color, lw=2, label=f'{low_text} Best Fit')\n",
    "    \n",
    "    # Add a vertical line at the normalization wavelength if specified\n",
    "    if normalize_at_wavelength is not None:\n",
    "        ax.axvline(x=normalize_at_wavelength, color='gray', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add a grid for reference\n",
    "    ax.grid(True, alpha=0.2)\n",
    "    \n",
    "    # Add a legend with both spectra\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    \n",
    "    # Add title and labels\n",
    "    \"\"\"title = f'Galaxy Spectra Comparison'\n",
    "    if normalize_at_wavelength is not None:\n",
    "        title += f' (Normalized at {normalize_at_wavelength}Å)'\n",
    "    ax.set_title(title, fontsize=20)\"\"\"\n",
    "    ax.set_xlabel('Wavelength (Å)', fontsize=15)\n",
    "    ax.set_ylabel('Relative Flux', fontsize=15)\n",
    "    \n",
    "    # Final adjustments\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(path, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Usage with normalization at 4000Å\n",
    "make_ppxf_plots_overlaid(\n",
    "    pp_high, pp_low,\n",
    "    high_text=\"High DoR\", \n",
    "    low_text=\"Low DoR\",\n",
    "    y_offset=0.0,  # Adjust this value to control vertical separation\n",
    "    path=\"../outputs/make_plots_output/overlaid_stellar_pop_comparison.png\",\n",
    "    normalize_at_wavelength=4800  # Normalize both spectra at 4000Å\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Figure 8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 7))\n",
    "props = dict(boxstyle='square', facecolor='white', alpha=0.8, edgecolor='black')\n",
    "\n",
    "# Create a smaller dataframe with just the two galaxies you want to plot\n",
    "# Example: choose galaxies 0 and 2 from your stacked regression set\n",
    "galaxy_ids = [0, 2]  # indices of the galaxies you want to plot\n",
    "df_subset = pd.DataFrame({\n",
    "    \"filename\": [f\"data/stacked_fits/stacked_REGRESSION_{id}.fits\" for id in galaxy_ids]\n",
    "})\n",
    "\n",
    "for idx, (index, row) in enumerate(df_subset.iterrows()):\n",
    "    # Get the file ID\n",
    "    galaxy_id = galaxy_ids[idx]\n",
    "    \n",
    "    # Set up your file paths as in your original code\n",
    "    fitsfile1 = f'../outputs/ppxf_fits/stacked_REGRESSION_{galaxy_id}_ppxfout_UNR.fits'\n",
    "    fitsfile2 = f'../outputs/ppxf_fits/stacked_REGRESSION_{galaxy_id}_ppxfout_REGUL.fits'\n",
    "    \n",
    "    # Process the files exactly as in your original code\n",
    "    name1, z1, agesplot1, weiplot1, univ_age1 = read_fits_summary(fitsfile1)\n",
    "    name2, z2, agesplot2, weiplot2, univ_age2 = read_fits_summary(fitsfile2)\n",
    "\n",
    "    masses = [weiplot1, weiplot2]\n",
    "    mean_masses = np.mean(masses, axis=0)\n",
    "    std_masses = np.std(masses, axis=0)\n",
    "\n",
    "    # Plot using the appropriate subplot (index 0 or 1)\n",
    "    ax = axs[idx]\n",
    "    \n",
    "    # The rest is the same as your original code, but using ax instead of axs[index%3,index//3]\n",
    "    ax.set_xlim(0, 13.5)\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.set_xlabel('Time since BB (Gyr)', fontsize=15)\n",
    "    ax.set_ylabel(r'Cumulative mass \\%', fontsize=15)\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(axis='both', which='both', direction='in', labelsize=15)\n",
    "    \n",
    "    ax.axhline(0.75, color='gray', alpha=0.2)\n",
    "    ax.text(12, 0.76, r'75\\%', style='italic', color='gray', fontsize=10)\n",
    "    ax.axhline(0.95, color='gray', alpha=0.2)\n",
    "    ax.text(12, 0.96, r'95\\%', style='italic', color='gray', fontsize=10)\n",
    "    ax.axvline(3.0, color='gray', alpha=0.2, linestyle='-.', linewidth=2.0)\n",
    "    ax.axvline(univ_age1, color='gray', linestyle='-.', linewidth=2.0)\n",
    "\n",
    "    # Add custom labels for High DoR and Low DoR\n",
    "    label = \"High DoR\" if idx == 0 else \"Low DoR\"\n",
    "    ax.text(0.8, 0.1, label, transform=ax.transAxes, fontsize=15,\n",
    "            verticalalignment='top', bbox=props, ha='center')\n",
    "    \n",
    "    ax.plot(agesplot1, mean_masses, color='black', linewidth=3.0)\n",
    "    ax.fill_between(agesplot1, mean_masses-std_masses, mean_masses+std_masses, color='black', alpha=0.1)\n",
    "    \n",
    "    ax.text(univ_age1-0.1, 0.1, 'today', color='gray', style='italic', rotation=90, \n",
    "            horizontalalignment='right', fontsize=10)\n",
    "    ax.text(2.9, 0.0, r'z$\\sim$2', style='italic', color='gray', rotation=90, \n",
    "            horizontalalignment='right', fontsize=10)\n",
    "    ax.set_xticks([0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0])\n",
    "    ax.set_yticklabels([f\"{tick*100:.0f}\" for tick in ax.get_yticks()])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/make_plots_output/mass_formation_over_time.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Figure 10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_e2 = pd.read_csv('../outputs/stacked_catalogues/CATALOGUE_REGRESSION.csv')\n",
    "df_e1 = pd.read_csv('../data/ppxf_stel_pop_dor_final.csv')\n",
    "# Identify the essential columns needed for the plots\n",
    "\n",
    "# Calculate t_ass_err using numpy's nanstd function directly\n",
    "t_ass_values = np.nanstd([\n",
    "    (0.7 + (df_e2['univ_age'] - df_e2['time_100'])) / df_e2['univ_age'],\n",
    "    (0.7 + (df_e2['univ_age'] - df_e2['time_100_reg'])) / df_e2['univ_age'],\n",
    "    (0.7 + (df_e2['univ_age'] - df_e2['time_100_unr'])) / df_e2['univ_age'],\n",
    "    (0.7 + (df_e2['univ_age'] - df_e2['time_100_plus'])) / df_e2['univ_age'],\n",
    "    (0.7 + (df_e2['univ_age'] - df_e2['time_100_min'])) / df_e2['univ_age']\n",
    "], axis=0)\n",
    "\n",
    "df_e2['t_ass_err'] = t_ass_values\n",
    "\n",
    "\"\"\"df_for_std = pd.DataFrame()\n",
    "# Calculate the standard metric for each estimate of time_100\n",
    "df_for_std['reg'] = (0.7 + (df_e2['univ_age'] - df_e2['time_100_reg'])) / df_e2['univ_age']\n",
    "df_for_std['unreg'] = (0.7 + (df_e2['univ_age'] - df_e2['time_100_unr'])) / df_e2['univ_age']\n",
    "df_for_std['plus'] = (0.7 + (df_e2['univ_age'] - df_e2['time_100_plus'])) / df_e2['univ_age']\n",
    "df_for_std['minus'] = (0.7 + (df_e2['univ_age'] - df_e2['time_100_min'])) / df_e2['univ_age']\n",
    "# Calculate the standard deviation along rows, ignoring NaNs\n",
    "df_e2['t_ass_err'] = df_for_std.std(axis=1, skipna=True)\"\"\"\n",
    "\n",
    "print(df_e2['t_ass_err'])\n",
    "\n",
    "essential_cols = [\n",
    "    'dor', \n",
    "    'mass_frac', 'mass_frac_reg', 'mass_frac_unr', 'mass_frac_plus', 'mass_frac_min',\n",
    "    'time_75', 'time_75_reg', 'time_75_unr', 'time_75_plus', 'time_75_min',\n",
    "    'univ_age', 'time_100', 't_ass_err'\n",
    "]\n",
    "\n",
    "# Filter each dataframe to only include these columns (if they exist)\n",
    "df_e2_cols = [col for col in essential_cols if col in df_e2.columns]\n",
    "df_e1_cols = [col for col in essential_cols if col in df_e1.columns]\n",
    "\n",
    "# Create shortened dataframes\n",
    "df_e2_short = df_e2[df_e2_cols].copy()\n",
    "df_e1_short = df_e1[df_e1_cols].copy()\n",
    "\n",
    "# Add a source column to track the origin\n",
    "df_e2_short['source'] = 'E-INSPIRE II'\n",
    "df_e1_short['source'] = 'E-INSPIRE I'\n",
    "\n",
    "# Combine the dataframes\n",
    "combined_df = pd.concat([df_e2_short, df_e1_short], ignore_index=True)\n",
    "\n",
    "# Print the result to verify\n",
    "print(f\"Combined dataframe shape: {combined_df.shape}\")\n",
    "print(f\"Columns in combined dataframe: {combined_df.columns.tolist()}\")\n",
    "\n",
    "df = combined_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fig, axs = plt.subplots(3, 1, sharex=True, figsize=(5, 12))\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "# fig.subplots_adjust(hspace=0.01)\n",
    "\n",
    "# Create a mask for E-INSPIRE II and E-INSPIRE I data points\n",
    "mask_einspire_ii = df['source'] == 'E-INSPIRE II'\n",
    "mask_einspire_i = df['source'] == 'E-INSPIRE I'\n",
    "\n",
    "# First subplot - mass fraction\n",
    "axs[0].axvline(0.3, color='0.6', linestyle='-.', linewidth=1, zorder=0)\n",
    "axs[0].axvline(0.6, color='0.6', linestyle='-.', linewidth=1, zorder=0)\n",
    "axs[0].set_ylim(top=1.05, bottom=-0.3)\n",
    "\n",
    "# Calculate errors\n",
    "err_mass_frac = np.nanstd([df['mass_frac_reg'].values, df['mass_frac_unr'].values, df['mass_frac_plus'], df['mass_frac_min']], axis=0)\n",
    "\n",
    "# Plot E-INSPIRE II (in red)\n",
    "axs[0].errorbar(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'mass_frac'], \n",
    "                yerr=err_mass_frac[mask_einspire_ii], fmt='none', c='r', zorder=1, \n",
    "                capsize=2, elinewidth=1, capthick=1)\n",
    "axs[0].scatter(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'mass_frac'], \n",
    "               s=25, c='red', marker='o', linewidths=0.5, label='E-INSPIRE II', zorder=10)\n",
    "\n",
    "# Plot E-INSPIRE I (in black)\n",
    "axs[0].errorbar(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'mass_frac'], \n",
    "                yerr=err_mass_frac[mask_einspire_i], fmt='none', c='grey', zorder=1, \n",
    "                capsize=1.5, elinewidth=0.3, capthick=0.3)\n",
    "axs[0].scatter(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'mass_frac'], \n",
    "               s=5, c='grey', label='E-INSPIRE I')\n",
    "\n",
    "axs[0].set_xlabel('DoR')\n",
    "axs[0].set_ylabel(r'$f_{M^{\\star}_{t\\mathrm{BB}=3}}$')\n",
    "axs[0].minorticks_on()\n",
    "axs[0].tick_params(axis='both',which='major',direction='inout')\n",
    "axs[0].tick_params(axis='both',which='minor',direction='in')\n",
    "\n",
    "# Second subplot - time_75\n",
    "axs[1].axvline(0.3, color='0.6', linestyle='-.', linewidth=1, zorder=0)\n",
    "axs[1].axvline(0.6, color='0.6', linestyle='-.', linewidth=1, zorder=0)\n",
    "axs[1].set_ylim(top=15.5, bottom=0)\n",
    "\n",
    "# Calculate errors\n",
    "err_time_75 = np.nanstd([df['time_75_reg'].values, df['time_75_unr'].values, df['time_75_plus'], df['time_75_min']], axis=0)\n",
    "\n",
    "# Plot E-INSPIRE II (in red)\n",
    "axs[1].errorbar(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'time_75'], \n",
    "                yerr=err_time_75[mask_einspire_ii], fmt='none', c='r', zorder=1, \n",
    "                capsize=2, elinewidth=1, capthick=1)\n",
    "axs[1].scatter(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'time_75'], \n",
    "               s=25, c='red', marker='o', linewidths=0.5, zorder=10)\n",
    "\n",
    "# Plot E-INSPIRE I (in black)\n",
    "axs[1].errorbar(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'time_75'], \n",
    "                yerr=err_time_75[mask_einspire_i], fmt='none', c='grey', zorder=1, \n",
    "                capsize=1.5, elinewidth=0.3, capthick=0.3)\n",
    "axs[1].scatter(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'time_75'], \n",
    "               s=5, c='grey')\n",
    "\n",
    "axs[1].set_xlabel('DoR')\n",
    "axs[1].set_ylabel(r't$_{75}$ [Gyr]')\n",
    "axs[1].minorticks_on()\n",
    "axs[1].tick_params(axis='both',which='major',direction='inout')\n",
    "axs[1].tick_params(axis='both',which='minor',direction='in')\n",
    "\n",
    "# Third subplot - universe age calculation\n",
    "axs[2].axvline(0.3, color='0.6', linestyle='-.', linewidth=1, zorder=0)\n",
    "axs[2].axvline(0.6, color='0.6', linestyle='-.', linewidth=1, zorder=0)\n",
    "\n",
    "# Calculate the ratio values\n",
    "ratio_values = (np.array(df['univ_age'])-np.array(df['time_100']))/np.array(df['univ_age'])\n",
    "#ratio_values = np.array(df['time_100'])\n",
    "\n",
    "# Plot E-INSPIRE II (in red)\n",
    "axs[2].errorbar(df.loc[mask_einspire_ii, 'dor'], ratio_values[mask_einspire_ii], \n",
    "                fmt='none', yerr=df.loc[mask_einspire_ii, 't_ass_err'], c='r', zorder=1, \n",
    "                capsize=2, elinewidth=1, capthick=1)\n",
    "axs[2].scatter(df.loc[mask_einspire_ii, 'dor'], ratio_values[mask_einspire_ii], \n",
    "               s=25, c='red', marker='o', linewidths=0.5, zorder=10)\n",
    "\n",
    "# Plot E-INSPIRE I (in black)\n",
    "axs[2].errorbar(df.loc[mask_einspire_i, 'dor'], ratio_values[mask_einspire_i], \n",
    "                fmt='none', yerr=df.loc[mask_einspire_i, 't_ass_err'], c='grey', zorder=1, \n",
    "                capsize=1.5, elinewidth=0.3, capthick=0.3)\n",
    "axs[2].scatter(df.loc[mask_einspire_i, 'dor'], ratio_values[mask_einspire_i], \n",
    "               s=5, c='grey')\n",
    "\n",
    "axs[2].set_xlabel('DoR')\n",
    "axs[2].set_xticks([0, 0.2, 0.4, 0.6, 0.8])\n",
    "axs[2].set_ylabel(r'$(t_{\\mathrm{Uni}} - t_{\\mathrm{fin}})/t_{\\mathrm{Uni}}$')\n",
    "axs[2].minorticks_on()\n",
    "axs[2].tick_params(axis='both',which='major',direction='inout')\n",
    "axs[2].tick_params(axis='both',which='minor',direction='in')\n",
    "\n",
    "# Add legend at the top of the figure\n",
    "plt.figlegend(loc='upper center', bbox_to_anchor=(0.5, 1.05), ncol=2, fontsize=12, fancybox=False, edgecolor='black')\n",
    "\n",
    "# Optional: Adjust layout to make room for the legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.savefig('../outputs/make_plots_output/E2_times_comparisons.png', bbox_inches='tight', dpi=300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Figure 11\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_e2 = pd.read_csv('../outputs/stacked_catalogues/CATALOGUE_REGRESSION.csv')\n",
    "df_e1 = pd.read_csv('../data/ppxf_stel_pop_dor_final.csv')  # Assuming this is your second dataframe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "'''# Load both dataframes\n",
    "df_e2 = pd.read_csv('../outputs/stacked_catalogues/CATALOGUE_REGRESSION.csv')\n",
    "df_e1 = pd.read_csv('../data/ppxf_stel_pop_dor_final.csv')  # Assuming this is your second dataframe\n",
    "\n",
    "# Rename columns in df_e1 to match df_e2 if needed\n",
    "# This is just an example - you'll need to adjust based on your actual column names\n",
    "column_mapping = {\n",
    "    # df_e1 column name: df_e2 column name\n",
    "    'velDisp_ppxf': 'vel_disp_avg',\n",
    "    'velDisp_ppxf_err': 'vel_disp_err',\n",
    "    \n",
    "}\n",
    "\n",
    "# Rename columns in df_e1\n",
    "df_e1 = df_e1.rename(columns=column_mapping)\n",
    "df_e1['age_mean'] = 10**df_e1['logAge_mean']\n",
    "\n",
    "# Process df_e2\n",
    "df_e2['age_mean'] = 10**df_e2['logAge']\n",
    "df_e2['age_min'] = 10**df_e2['logAge_minus']\n",
    "df_e2['age_plus'] = 10**df_e2['logAge_plus']\n",
    "\n",
    "df_e2['age_err_lower'] = abs(df_e2['age_mean'] - df_e2['age_min'])\n",
    "df_e2['age_err_upper'] = abs(df_e2['age_plus'] - df_e2['age_mean'])\n",
    "df_e2['age_err'] = (df_e2['age_err_lower'] + df_e2['age_err_upper']) / 2\n",
    "\n",
    "df_e2['[M/H]_mean'] = df_e2['[M/H]']\n",
    "df_e2['[M/H]_err_lower'] = abs(df_e2['[M/H]_mean'] - df_e2['[M/H]_minus'])\n",
    "df_e2['[M/H]_err_upper'] = abs(df_e2['[M/H]_plus'] - df_e2['[M/H]_mean'])\n",
    "df_e2['[M/H]_err'] = (df_e2['[M/H]_err_lower'] + df_e2['[M/H]_err_upper']) / 2\n",
    "\n",
    "\n",
    "df_e2['source'] = 'E-INSPIRE II'\n",
    "df_e1['source'] = 'E-INSPIRE I'\n",
    "\n",
    "# Combine the dataframes\n",
    "# Use only columns that exist in both dataframes\n",
    "common_columns = list(set(df_e2.columns).intersection(set(df_e1.columns)))\n",
    "df_e2_subset = df_e2[common_columns]\n",
    "df_e1_subset = df_e1[common_columns]\n",
    "df = pd.concat([df_e2_subset, df_e1_subset], ignore_index=True)\n",
    "\n",
    "# Create masks for plotting\n",
    "mask_einspire_ii = df['source'] == 'E-INSPIRE II'\n",
    "mask_einspire_i = df['source'] == 'E-INSPIRE I'\n",
    "\n",
    "# Create the figure and subplots\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "# First subplot: Velocity dispersion\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[0, 0].errorbar(df.loc[mask_einspire_i, 'dor'], np.log10(df.loc[mask_einspire_i, 'vel_disp_avg']), \n",
    "                  yerr=(df.loc[mask_einspire_i, 'vel_disp_err']/df.loc[mask_einspire_i, 'vel_disp_avg'])/np.log(10), \n",
    "                  fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[0, 0].scatter(df.loc[mask_einspire_i, 'dor'], np.log10(df.loc[mask_einspire_i, 'vel_disp_avg']), \n",
    "                 s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[0, 0].errorbar(df.loc[mask_einspire_ii, 'dor'], np.log10(df.loc[mask_einspire_ii, 'vel_disp_avg']), \n",
    "                  yerr=(df.loc[mask_einspire_ii, 'vel_disp_err']/df.loc[mask_einspire_ii, 'vel_disp_avg'])/np.log(10), \n",
    "                  fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[0, 0].scatter(df.loc[mask_einspire_ii, 'dor'], np.log10(df.loc[mask_einspire_ii, 'vel_disp_avg']), \n",
    "                 s=30, c='red', marker='o', linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[0, 0].set_xlabel('DoR')\n",
    "axs[0, 0].set_ylabel(r'$\\log(\\sigma_{\\star}$ [km/s])')\n",
    "axs[0, 0].minorticks_on()\n",
    "axs[0, 0].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "# Second subplot: Stellar age\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[0, 1].errorbar(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'age_mean'], \n",
    "                  yerr=df.loc[mask_einspire_i, 'age_err'], \n",
    "                  fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[0, 1].scatter(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'age_mean'], \n",
    "                 s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[0, 1].errorbar(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'age_mean'], \n",
    "                  yerr=df.loc[mask_einspire_ii, 'age_err'], \n",
    "                  fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[0, 1].scatter(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'age_mean'], \n",
    "                 s=30, c='red', marker='o', linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[0, 1].set_xlabel('DoR')\n",
    "axs[0, 1].set_ylabel('Stellar age [Gyr]')\n",
    "axs[0, 1].minorticks_on()\n",
    "axs[0, 1].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "# Third subplot: Metallicity\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[0, 2].errorbar(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, '[M/H]_mean'], \n",
    "                  yerr=df.loc[mask_einspire_i, '[M/H]_err'], \n",
    "                  fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[0, 2].scatter(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, '[M/H]_mean'], \n",
    "                 s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[0, 2].errorbar(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, '[M/H]_mean'], \n",
    "                  yerr=df.loc[mask_einspire_ii, '[M/H]_err'], \n",
    "                  fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[0, 2].scatter(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, '[M/H]_mean'], \n",
    "                 s=30, c='red', marker='o',linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[0, 2].set_xlabel('DoR')\n",
    "axs[0, 2].set_ylabel('[M/H]')\n",
    "axs[0, 2].minorticks_on()\n",
    "axs[0, 2].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "# Fourth subplot: Stellar mass\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[1, 0].errorbar(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'logM'], \n",
    "                  yerr=df.loc[mask_einspire_i, 'errlogM'], \n",
    "                  fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[1, 0].scatter(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'logM'], \n",
    "                 s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[1, 0].errorbar(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'logM'], \n",
    "                  yerr=df.loc[mask_einspire_ii, 'errlogM'], \n",
    "                  fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[1, 0].scatter(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'logM'], \n",
    "                 s=30, c='red', marker='o', linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[1, 0].set_xlabel('DoR')\n",
    "axs[1, 0].set_ylabel(r'$\\log(\\rm M_{\\star}\\,[\\rm M_{\\odot}])$')\n",
    "axs[1, 0].minorticks_on()\n",
    "axs[1, 0].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "# Fifth subplot: Effective radius\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[1, 1].errorbar(df.loc[mask_einspire_i, 'dor'], np.log10(df.loc[mask_einspire_i, 'meanRadkpc_r']), \n",
    "                  yerr=(df.loc[mask_einspire_i, 'meanRadErrkpc_r']/df.loc[mask_einspire_i, 'meanRadkpc_r'])/np.log(10), \n",
    "                  fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[1, 1].scatter(df.loc[mask_einspire_i, 'dor'], np.log10(df.loc[mask_einspire_i, 'meanRadkpc_r']), \n",
    "                 s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[1, 1].errorbar(df.loc[mask_einspire_ii, 'dor'], np.log10(df.loc[mask_einspire_ii, 'meanRadkpc_r']), \n",
    "                  yerr=(df.loc[mask_einspire_ii, 'meanRadErrkpc_r']/df.loc[mask_einspire_ii, 'meanRadkpc_r'])/np.log(10), \n",
    "                  fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[1, 1].scatter(df.loc[mask_einspire_ii, 'dor'], np.log10(df.loc[mask_einspire_ii, 'meanRadkpc_r']), \n",
    "                 s=30, c='red', marker='o', linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[1, 1].set_xlabel('DoR')\n",
    "axs[1, 1].set_ylabel(r'$\\log(\\rm R_e$ [kpc])')\n",
    "axs[1, 1].minorticks_on()\n",
    "axs[1, 1].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "# Sixth subplot: sSFR\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[1, 2].errorbar(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'logsSFR'], \n",
    "                  yerr=df.loc[mask_einspire_i, 'errlogsSFR'], \n",
    "                  fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[1, 2].scatter(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'logsSFR'], \n",
    "                 s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[1, 2].errorbar(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'logsSFR'], \n",
    "                  yerr=df.loc[mask_einspire_ii, 'errlogsSFR'], \n",
    "                  fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[1, 2].scatter(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'logsSFR'], \n",
    "                 s=30, c='red', marker='o', linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[1, 2].set_xlabel('DoR')\n",
    "axs[1, 2].set_ylabel(r'$\\log(\\rm sSFR~[yr^{-1}])$')\n",
    "axs[1, 2].minorticks_on()\n",
    "axs[1, 2].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "# Add a legend to the figure\n",
    "# Create custom handles for the legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', \n",
    "             markersize=10, label='E-INSPIRE II'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='grey', \n",
    "           markersize=5, label='E-INSPIRE I')\n",
    "]\n",
    "fig.legend(handles=legend_elements, loc='upper center', \n",
    "           bbox_to_anchor=(0.5, 1.01), ncol=2, fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])'''\n",
    "\n",
    "print(\"SkipME\")\n",
    "# This is the version with all 6 graphs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Version with only top row\n",
    "df_e2 = pd.read_csv('../outputs/stacked_catalogues/CATALOGUE_REGRESSION.csv')\n",
    "df_e1 = pd.read_csv('../data/ppxf_stel_pop_dor_final.csv')  # Assuming this is your second dataframe\n",
    "\n",
    "column_mapping = {\n",
    "    # df_e1 column name: df_e2 column name\n",
    "    'velDisp_ppxf': 'vel_disp_avg',\n",
    "    'velDisp_ppxf_err': 'vel_disp_err',\n",
    "    \n",
    "}\n",
    "\n",
    "# Rename columns in df_e1\n",
    "df_e1 = df_e1.rename(columns=column_mapping)\n",
    "df_e1['age_mean'] = 10**df_e1['logAge_mean']\n",
    "\n",
    "# Process df_e2\n",
    "df_e2['age_mean'] = 10**df_e2['logAge']\n",
    "df_e2['age_min'] = 10**df_e2['logAge_minus']\n",
    "df_e2['age_plus'] = 10**df_e2['logAge_plus']\n",
    "\n",
    "df_e2['age_err_lower'] = abs(df_e2['age_mean'] - df_e2['age_min'])\n",
    "df_e2['age_err_upper'] = abs(df_e2['age_plus'] - df_e2['age_mean'])\n",
    "df_e2['age_err'] = (df_e2['age_err_lower'] + df_e2['age_err_upper']) / 2\n",
    "\n",
    "df_e2['[M/H]_mean'] = df_e2['[M/H]']\n",
    "df_e2['[M/H]_err_lower'] = abs(df_e2['[M/H]_mean'] - df_e2['[M/H]_minus'])\n",
    "df_e2['[M/H]_err_upper'] = abs(df_e2['[M/H]_plus'] - df_e2['[M/H]_mean'])\n",
    "df_e2['[M/H]_err'] = (df_e2['[M/H]_err_lower'] + df_e2['[M/H]_err_upper']) / 2\n",
    "\n",
    "\n",
    "df_e2['source'] = 'E-INSPIRE II'\n",
    "df_e1['source'] = 'E-INSPIRE I'\n",
    "\n",
    "# Combine the dataframes\n",
    "# Use only columns that exist in both dataframes\n",
    "common_columns = list(set(df_e2.columns).intersection(set(df_e1.columns)))\n",
    "df_e2_subset = df_e2[common_columns]\n",
    "df_e1_subset = df_e1[common_columns]\n",
    "df = pd.concat([df_e2_subset, df_e1_subset], ignore_index=True)\n",
    "\n",
    "# Create masks for plotting\n",
    "mask_einspire_ii = df['source'] == 'E-INSPIRE II'\n",
    "mask_einspire_i = df['source'] == 'E-INSPIRE I'\n",
    "\n",
    "# Create the figure and subplots - modified to only have 1 row with 3 columns\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# First subplot: Velocity dispersion\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[0].errorbar(df.loc[mask_einspire_i, 'dor'], np.log10(df.loc[mask_einspire_i, 'vel_disp_avg']), \n",
    "                yerr=(df.loc[mask_einspire_i, 'vel_disp_err']/df.loc[mask_einspire_i, 'vel_disp_avg'])/np.log(10), \n",
    "                fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[0].scatter(df.loc[mask_einspire_i, 'dor'], np.log10(df.loc[mask_einspire_i, 'vel_disp_avg']), \n",
    "              s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[0].errorbar(df.loc[mask_einspire_ii, 'dor'], np.log10(df.loc[mask_einspire_ii, 'vel_disp_avg']), \n",
    "                yerr=(df.loc[mask_einspire_ii, 'vel_disp_err']/df.loc[mask_einspire_ii, 'vel_disp_avg'])/np.log(10), \n",
    "                fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[0].scatter(df.loc[mask_einspire_ii, 'dor'], np.log10(df.loc[mask_einspire_ii, 'vel_disp_avg']), \n",
    "              s=30, c='red', marker='o', linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[0].set_xlabel('DoR')\n",
    "axs[0].set_ylabel(r'$\\log(\\sigma_{\\star}$ [km/s])')\n",
    "axs[0].minorticks_on()\n",
    "axs[0].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "# Second subplot: Stellar age\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[1].errorbar(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'age_mean'], \n",
    "                yerr=df.loc[mask_einspire_i, 'age_err'], \n",
    "                fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[1].scatter(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, 'age_mean'], \n",
    "              s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[1].errorbar(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'age_mean'], \n",
    "                yerr=df.loc[mask_einspire_ii, 'age_err'], \n",
    "                fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[1].scatter(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, 'age_mean'], \n",
    "              s=30, c='red', marker='o', linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[1].set_xlabel('DoR')\n",
    "axs[1].set_ylabel('Stellar age [Gyr]')\n",
    "axs[1].minorticks_on()\n",
    "axs[1].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "# Third subplot: Metallicity\n",
    "# Plot E-INSPIRE I (grey) points first\n",
    "axs[2].errorbar(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, '[M/H]_mean'], \n",
    "                yerr=df.loc[mask_einspire_i, '[M/H]_err'], \n",
    "                fmt='none', c='grey', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9, alpha=0.7)\n",
    "axs[2].scatter(df.loc[mask_einspire_i, 'dor'], df.loc[mask_einspire_i, '[M/H]_mean'], \n",
    "              s=5, c='grey', alpha=0.7)\n",
    "\n",
    "# Plot E-INSPIRE II (red) points on top\n",
    "axs[2].errorbar(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, '[M/H]_mean'], \n",
    "                yerr=df.loc[mask_einspire_ii, '[M/H]_err'], \n",
    "                fmt='none', c='r', zorder=9, capsize=3, elinewidth=1.5, capthick=1.5)\n",
    "axs[2].scatter(df.loc[mask_einspire_ii, 'dor'], df.loc[mask_einspire_ii, '[M/H]_mean'], \n",
    "              s=30, c='red', marker='o',linewidths=0.7, zorder=10)\n",
    "\n",
    "axs[2].set_xlabel('DoR')\n",
    "axs[2].set_ylabel('[M/H]')\n",
    "axs[2].minorticks_on()\n",
    "axs[2].set_xticks([0., 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='red', \n",
    "             markersize=10, label='E-INSPIRE II'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='grey', \n",
    "           markersize=5, label='E-INSPIRE I')\n",
    "]\n",
    "fig.legend(handles=legend_elements, loc='upper center', \n",
    "           bbox_to_anchor=(0.5, 1.01), ncol=2, fontsize=12)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig('../outputs/make_plots_output/E2_params_comparisons.png', bbox_inches='tight', dpi=300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Figure 13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "custom_df = pd.read_csv('../outputs/stacked_catalogues/CATALOGUE_REGRESSION.csv')\n",
    "custom_df['[M/H]_mean'] = custom_df['[M/H]']\n",
    "custom_df['[M/H]_err_lower'] = abs(custom_df['[M/H]_mean'] - custom_df['[M/H]_minus'])\n",
    "custom_df['[M/H]_err_upper'] = abs(custom_df['[M/H]_plus'] - custom_df['[M/H]_mean'])\n",
    "custom_df['[M/H]_err'] = (custom_df['[M/H]_err_lower'] + custom_df['[M/H]_err_upper']) / 2\n",
    "\n",
    "print(custom_df.columns)\n",
    "\n",
    "custom_df = custom_df.sort_values(by='logM')\n",
    "custom_df = custom_df.rename(columns={\n",
    "    #'[M/H]': '[M/H]_mean',\n",
    "    'vel_disp_avg': 'velDisp_ppxf'\n",
    "})\n",
    "\n",
    "df = pd.read_csv('../data/ppxf_stel_pop_dor_final.csv')\n",
    "df1 = df[df['dor'] <= 0.3]\n",
    "df2 = df[(df['dor'] > 0.3) & (df['dor'] <= 0.6)]\n",
    "df3 = df[df['dor'] > 0.6]\n",
    "\n",
    "# Define the bin edges\n",
    "bins = np.arange(df['logM'].min(), df['logM'].max(), 0.1)\n",
    "\n",
    "# Create new columns in each dataframe with the bin labels\n",
    "df1['mass_bin'] = pd.cut(df1['logM'], bins=bins)\n",
    "df2['mass_bin'] = pd.cut(df2['logM'], bins=bins)\n",
    "df3['mass_bin'] = pd.cut(df3['logM'], bins=bins)\n",
    "df1_grouped = df1.groupby('mass_bin')[['[M/H]_mean', 'dor', 'logM']].agg(['mean', 'std'])\n",
    "df2_grouped = df2.groupby('mass_bin')[['[M/H]_mean', 'dor', 'logM']].agg(['mean', 'std'])\n",
    "df3_grouped = df3.groupby('mass_bin')[['[M/H]_mean', 'dor', 'logM']].agg(['mean', 'std'])\n",
    "\n",
    "# For each dataframe, group by mass_bin and compute mean and std\n",
    "df1_groupeda = df1.groupby('mass_bin')[['velDisp_ppxf', 'dor', 'logM']].agg(['mean', 'std'])\n",
    "df2_groupeda = df2.groupby('mass_bin')[['velDisp_ppxf', 'dor', 'logM']].agg(['mean', 'std'])\n",
    "df3_groupeda = df3.groupby('mass_bin')[['velDisp_ppxf', 'dor', 'logM']].agg(['mean', 'std'])\n",
    "\n",
    "# Create the figure\n",
    "fig, axs = plt.subplots(2, 1, figsize=(6,10), sharex=True, height_ratios=[1.25, 1])\n",
    "fig.subplots_adjust(hspace=0.01)\n",
    "cmap = plt.get_cmap('Spectral_r')\n",
    "norm = plt.Normalize(df['dor'].min(), df['dor'].max())\n",
    "\n",
    "# Plot existing grouped data\n",
    "axs[0].errorbar(df1_grouped['logM']['mean'], df1_grouped['[M/H]_mean']['mean'], xerr=df1_grouped['logM']['std'], yerr=df1_grouped['[M/H]_mean']['std'], fmt='none', c='0.7', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9)\n",
    "axs[0].errorbar(df2_grouped['logM']['mean'], df2_grouped['[M/H]_mean']['mean'], xerr=df2_grouped['logM']['std'], yerr=df2_grouped['[M/H]_mean']['std'], fmt='none', c='0.7', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9)\n",
    "axs[0].errorbar(df3_grouped['logM']['mean'], df3_grouped['[M/H]_mean']['mean'], xerr=df3_grouped['logM']['std'], yerr=df3_grouped['[M/H]_mean']['std'], fmt='none', c='0.7', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9)\n",
    "axs[0].scatter(df1_grouped['logM']['mean'], df1_grouped['[M/H]_mean']['mean'], c=cmap(norm(df1_grouped['dor']['mean'])))\n",
    "axs[0].scatter(df2_grouped['logM']['mean'], df2_grouped['[M/H]_mean']['mean'], c=cmap(norm(df2_grouped['dor']['mean'])))\n",
    "axs[0].scatter(df3_grouped['logM']['mean'], df3_grouped['[M/H]_mean']['mean'], c=cmap(norm(df3_grouped['dor']['mean'])))\n",
    "\n",
    "axs[1].errorbar(df1_groupeda['logM']['mean'], df1_groupeda['velDisp_ppxf']['mean'], xerr=df1_groupeda['logM']['std'], yerr=df1_groupeda['velDisp_ppxf']['std'], fmt='none', c='0.7', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9)\n",
    "axs[1].errorbar(df2_groupeda['logM']['mean'], df2_groupeda['velDisp_ppxf']['mean'], xerr=df2_groupeda['logM']['std'], yerr=df2_groupeda['velDisp_ppxf']['std'], fmt='none', c='0.7', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9)\n",
    "axs[1].errorbar(df3_groupeda['logM']['mean'], df3_groupeda['velDisp_ppxf']['mean'], xerr=df3_groupeda['logM']['std'], yerr=df3_groupeda['velDisp_ppxf']['std'], fmt='none', c='0.7', zorder=0, capsize=2, elinewidth=0.9, capthick=0.9)\n",
    "axs[1].scatter(df1_groupeda['logM']['mean'], df1_groupeda['velDisp_ppxf']['mean'], c=cmap(norm(df1_groupeda['dor']['mean'])))\n",
    "axs[1].scatter(df2_groupeda['logM']['mean'], df2_groupeda['velDisp_ppxf']['mean'], c=cmap(norm(df2_groupeda['dor']['mean'])))\n",
    "axs[1].scatter(df3_groupeda['logM']['mean'], df3_groupeda['velDisp_ppxf']['mean'], c=cmap(norm(df3_groupeda['dor']['mean'])))\n",
    "\n",
    "# Plot the custom points from CATALOGUE_REGRESSION.csv with error bars\n",
    "custom_points = custom_df.head(3)  # Get the first 3 rows\n",
    "for _, point in custom_points.iterrows():\n",
    "    # If 'dor' is not in the custom dataframe, assign a default value or create a formula\n",
    "    if 'dor' not in custom_df.columns:\n",
    "        dor_value = 0.5  # Default middle value, or choose appropriate value\n",
    "    else:\n",
    "        dor_value = point['dor']\n",
    "    \n",
    "    # First plot error bars for metallicity panel (upper)\n",
    "    axs[0].errorbar(\n",
    "        point['logM'], \n",
    "        point['[M/H]_mean'], \n",
    "        xerr=point['errlogM'] if 'errlogM' in point else None,\n",
    "        yerr=point['[M/H]_err'] if '[M/H]_err' in point else None,\n",
    "        fmt='none', \n",
    "        ecolor='black',\n",
    "        capsize=3,\n",
    "        elinewidth=1.2,\n",
    "        capthick=1.2,\n",
    "        zorder=9\n",
    "    )\n",
    "    \n",
    "    # Then plot error bars for velocity dispersion panel (lower)\n",
    "    axs[1].errorbar(\n",
    "        point['logM'], \n",
    "        point['velDisp_ppxf'], \n",
    "        xerr=point['errlogM'] if 'errlogM' in point else None,\n",
    "        yerr=point['vel_disp_err'] if 'vel_disp_err' in point else None,\n",
    "        fmt='none', \n",
    "        ecolor='black',\n",
    "        capsize=3,\n",
    "        elinewidth=1.2,\n",
    "        capthick=1.2,\n",
    "        zorder=9\n",
    "    )\n",
    "    \n",
    "    # Plot the actual points on top of error bars\n",
    "    # Plot in the metallicity panel (upper)\n",
    "    axs[0].scatter(point['logM'], point['[M/H]_mean'], c=cmap(norm(dor_value)), \n",
    "                  marker='o', s=100, edgecolor='black', linewidth=1.5, zorder=10)\n",
    "    \n",
    "    # Plot in the velocity dispersion panel (lower)\n",
    "    axs[1].scatter(point['logM'], point['velDisp_ppxf'], c=cmap(norm(dor_value)),\n",
    "                  marker='o', s=100, edgecolor='black', linewidth=1.5, zorder=10)\n",
    "\n",
    "# Add a legend for the custom points\n",
    "axs[0].scatter([], [], c='gray', marker='o', s=150, edgecolor='black', linewidth=1.5, label='Stacked points')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[0].set_ylabel(r'[M/H]')\n",
    "axs[0].minorticks_on()\n",
    "axs[0].tick_params(axis='both',which='both',direction='in', right=True, top=True)\n",
    "\n",
    "axs[1].set_xlabel(r'$\\log(\\rm M_{\\star}$ $\\rm [M_{\\odot}])$')\n",
    "axs[1].set_ylabel(r'$\\sigma_{\\star}$ [km/s]')\n",
    "axs[1].minorticks_on()\n",
    "axs[1].tick_params(axis='both',which='both',direction='in', right=True, top=True)\n",
    "\n",
    "cb = fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), ax=axs[0], label='DoR', location='top')\n",
    "cb.minorticks_on()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/make_plots_output/mass_metallicity_velocity.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
